{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab097f6c-7095-491a-8fc6-0e7279daedcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting entry_point.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile entry_point.py\n",
    "import argparse\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from io import StringIO\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, 'model.joblib'))\n",
    "    return model\n",
    "\n",
    "def predict_fn(input_object, model):\n",
    "    y_pred = model.predict_proba(input_object)[0][1]\n",
    "    return y_pred\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print(request_body)\n",
    "   \n",
    "    df = pd.read_csv(StringIO(request_body), header=None)\n",
    "   \n",
    "    print(df)\n",
    "   \n",
    "    return df.to_numpy()\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    train = pd.read_csv('{}/train.csv'.format(args.train), header=None)\n",
    "    test = pd.read_csv('{}/test.csv'.format(args.test), header=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = train.iloc[:, 1:]\n",
    "    y_train = train.iloc[:, 0]\n",
    "    \n",
    "    X_test = test.iloc[:, 1:]\n",
    "    y_test = test.iloc[:, 0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train = pd.to_datetime(X_train)\n",
    "    X_train = X_train.map(dt.datetime.toordinal)\n",
    "    \n",
    "    X_test = pd.to_datetime(X_test)\n",
    "    X_test = X_test.map(dt.datetime.toordinal)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_test_predict = model.predict(X_test)\n",
    "    \n",
    "    puntuation = r2_score(y_test, y_test_predict)\n",
    "    mae = mean_absolute_error(y_test, y_test_predict)\n",
    "    mse = mean_squared_error(y_test, y_test_predict)\n",
    "    \n",
    "    print(f\"Coeficientes del modelo: {model.coef_}\")\n",
    "    print(f\"Intresección del modelo: {model.intercept_}\")\n",
    "    print(f\"Número de coeficientes del modelo: {len(model.coef_)}\")\n",
    "    \n",
    "    print(f\"Score r2: {puntuation}\")\n",
    "    print(f\"Score mae: {mae}\")\n",
    "    print(f\"Score mse: {mse}\")\n",
    "    \n",
    "    joblib.dump(model, os.path.join(args.model_dir, 'model.joblib') )\n",
    "    \n",
    "    print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddae6cca-64ff-45fb-9c48-c16c46b43dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/final-project-dollar/entry_point.py\", line 53, in <module>\n",
      "    X_train = pd.to_datetime(X_train)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py\", line 1071, in to_datetime\n",
      "    result = _assemble_from_unit_mappings(arg, errors, tz)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py\", line 1178, in _assemble_from_unit_mappings\n",
      "    unit = {k: f(k) for k in arg.keys()}\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py\", line 1178, in <dictcomp>\n",
      "    unit = {k: f(k) for k in arg.keys()}\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/tools/datetimes.py\", line 1173, in f\n",
      "    if value.lower() in _unit_map:\n",
      "AttributeError: 'int' object has no attribute 'lower'\n"
     ]
    }
   ],
   "source": [
    "!python entry_point.py --train s3://final-dollar-semestre3-sa/dollar/train --test s3://final-dollar-semestre3-sa/dollar/test --model-dir ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d188a88-dfca-402c-8a5a-afbbe698f05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56437b06-3bce-4e5f-96ab-1ae31cc0b914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"linear-learner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca991659-b607-40f0-a76e-6e8c1ddd8d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('data/train.csv', header=0)\n",
    "test = pd.read_csv('data/test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae7d49e9-dae6-48cd-a5e2-e6955ebb47c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 0]\n",
    "y_train = train.iloc[:, 1]\n",
    "\n",
    "X_test = test.iloc[:, 0]\n",
    "y_test = test.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "281ff731-79c4-44a7-8766-e7908fbcf3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " len X_train:<class 'pandas.core.series.Series'>, len X_test:<class 'pandas.core.series.Series'> \n",
      " len y_train:<class 'pandas.core.series.Series'>, len y_test:<class 'pandas.core.series.Series'> \n"
     ]
    }
   ],
   "source": [
    "X_train = pd.to_datetime(X_train)\n",
    "X_train = X_train.map(dt.datetime.toordinal)\n",
    "\n",
    "X_test = pd.to_datetime(X_test)\n",
    "X_test = X_test.map(dt.datetime.toordinal)\n",
    "\n",
    "print(f\" len X_train:{type(X_train)}, len X_test:{type(X_test)} \")\n",
    "print(f\" len y_train:{type(y_train)}, len y_test:{type(y_test)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "486f559f-ffe3-4d44-8d1e-49cf8a4ee232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train =  np.array(X_train).reshape(1, -1)\n",
    "X_test =  np.array(X_test).reshape(1, -1)\n",
    "\n",
    "y_train =  np.array(y_train).reshape(1, -1)\n",
    "y_test =  np.array(y_test).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99d0879f-d503-4d5f-ab8e-7df9ba98a951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " len X_train:692, len X_test:174 \n",
      " len y_train:692, len y_test:174 \n"
     ]
    }
   ],
   "source": [
    "print(f\" len X_train:{len(X_train[0])}, len X_test:{len(X_test[0])} \")\n",
    "print(f\" len y_train:{len(y_train[0])}, len y_test:{len(y_test[0])} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "718069f6-fa62-431d-8a51-77d42a2f1e02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 174 features, but LinearRegression is expecting 692 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:692\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m--> 692\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:355\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:338\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    336\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 338\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:558\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 558\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/base.py:359\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 174 features, but LinearRegression is expecting 692 features as input."
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcbbac53-ad82-4c09-a5c0-687effe29836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes del modelo: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Intresección del modelo: [4572.78   4572.9031 4572.8265 4573.0595 4573.1477 4573.2283 4573.37\n",
      " 4573.4327 4572.678  4572.6423 4572.2873 4572.2703 4572.2498 4571.7827\n",
      " 4571.7749 4571.7598 4571.745  4571.7114 4571.6523 4571.5208 4571.4096\n",
      " 4571.3696 4571.3303 4571.0371 4570.9884 4570.8047 4570.614  4570.5705\n",
      " 4570.5122 4570.4702 4570.4287 4570.3193 4570.2659 4569.3341 4569.2541\n",
      " 4569.2208 4569.1556 4569.1204 4568.9361 4568.8565 4568.7325 4568.6991\n",
      " 4568.3014 4568.1801 4568.0638 4567.9523 4567.8453 4567.8211 4567.7193\n",
      " 4567.6213 4567.5195 4567.4918 4567.4368 4567.15   4567.1287 4567.0854\n",
      " 4567.0634 4567.0481 4567.035  4567.0085 4567.006  4567.0046 4567.0045\n",
      " 4567.0045 4567.0043 4567.0043 4567.0002 4566.9978 4566.9938 4566.9917\n",
      " 4566.9838 4566.972  4566.9642 4566.9603 4566.9209 4566.8848 4566.8719\n",
      " 4566.8575 4566.8117 4566.7958 4566.7795 4566.7236 4566.6692 4566.5546\n",
      " 4566.4575 4566.4442 4566.4309 4566.398  4566.385  4566.3333 4566.3215\n",
      " 4566.3032 4566.2922 4566.2561 4566.2518 4566.2321 4566.2313 4566.2328\n",
      " 4566.2352 4566.2375 4566.2398 4566.2421 4566.2414 4566.2399 4566.2392\n",
      " 4566.2404 4566.2416 4566.2379 4566.2351 4566.2297 4566.2211 4566.2205\n",
      " 4566.2145 4566.2112 4566.2117 4566.2084 4566.199  4566.1806 4566.1531\n",
      " 4566.1363 4566.1279 4566.0013 4565.99   4565.9671 4565.9331 4565.8885\n",
      " 4565.8449 4565.8127 4565.7915 4565.7499 4565.7293 4565.7203 4565.7152\n",
      " 4565.7065 4565.6976 4565.6849 4565.6799 4565.675  4565.6701 4565.6506\n",
      " 4565.6456 4565.6266 4565.6126 4565.5849 4565.5487 4565.543  4565.5271\n",
      " 4565.5092 4565.5014 4565.4855 4565.4803 4565.4646 4565.4595 4565.4441\n",
      " 4565.4391 4565.434  4565.429  4565.424  4565.3678 4565.3628 4565.3346\n",
      " 4565.2886 4565.2862 4565.2789 4565.2763 4565.2563 4565.2646 4565.2675\n",
      " 4565.3022 4565.3074 4565.3107 4565.3204 4565.3604 4565.3564 4565.3558\n",
      " 4565.35   4565.3494 4565.3462 4565.3456 4565.3452 4565.341  4565.3316\n",
      " 4565.3323 4565.3334 4565.3322 4565.3702 4565.3748 4565.4191 4565.4234\n",
      " 4565.4287 4565.434  4565.4366 4565.4418 4565.4723 4565.4773 4565.4968\n",
      " 4565.5111 4565.5199 4565.5228 4565.5258 4565.5242 4565.522  4565.5204\n",
      " 4565.5189 4565.5173 4565.5082 4565.5052 4565.5021 4565.5006 4565.5014\n",
      " 4565.5021 4565.5076 4565.5111 4565.5147 4565.5186 4565.5237 4565.5287\n",
      " 4565.6524 4565.6469 4565.6535 4565.6628 4565.6809 4565.6898 4565.6987\n",
      " 4565.6992 4565.7113 4565.7234 4565.7354 4565.7394 4565.7412 4565.7426\n",
      " 4565.7465 4565.7493 4565.7534 4565.8371 4565.8494 4565.8535 4565.8576\n",
      " 4565.8657 4565.8819 4565.8859 4565.8899 4565.8939 4565.8979 4565.9018\n",
      " 4565.9097 4565.9137 4565.9176 4565.926  4565.9306 4565.9398 4565.9447\n",
      " 4565.9495 4566.1446 4566.1562 4566.1688 4566.1939 4566.2743 4566.2802\n",
      " 4566.2863 4566.358  4566.3698 4566.3815 4566.3873 4566.5219 4566.5292\n",
      " 4566.537  4566.5448 4566.553  4566.5652 4566.6722 4566.6808 4566.6877\n",
      " 4566.6935 4566.6993 4566.7051 4566.7108 4566.7167 4566.7234 4566.73\n",
      " 4566.8092 4566.8126 4566.816  4566.8216 4566.8276 4566.8405 4566.8534\n",
      " 4566.8598 4566.8661 4566.8852 4566.8918 4566.898  4566.9043 4566.9106\n",
      " 4566.9168 4566.9231 4566.9293 4566.9863 4566.994  4567.0018 4567.0096\n",
      " 4567.0173 4567.0251 4567.0414 4567.0495 4567.0577 4567.0659 4567.073\n",
      " 4567.0905 4567.1165 4567.1255 4567.1349 4567.1444 4567.1641 4567.174\n",
      " 4567.1814 4567.1888 4567.1957 4567.3895 4567.4071 4567.4157 4567.4242\n",
      " 4567.4328 4567.4412 4567.4497 4567.4607 4567.4716 4567.4826 4567.491\n",
      " 4567.499  4567.5096 4567.5169 4567.5365 4567.5482 4567.5544 4567.5607\n",
      " 4567.5686 4567.6003 4567.6084 4567.6402 4567.6641 4567.6721 4567.6909\n",
      " 4567.7007 4567.7425 4567.7832 4567.7934 4567.8035 4567.8443 4567.8662\n",
      " 4567.9021 4568.0318 4568.0439 4568.0562 4568.0691 4568.0965 4568.1265\n",
      " 4568.1419 4568.2671 4568.2832 4568.2993 4568.3153 4568.3312 4568.3789\n",
      " 4568.3946 4568.4101 4568.4232 4568.4364 4568.4757 4568.4888 4568.5278\n",
      " 4568.5538 4568.5796 4568.5925 4568.6053 4568.6337 4568.6481 4568.6769\n",
      " 4568.6912 4569.7756 4569.7895 4569.8067 4569.8201 4569.8319 4569.8467\n",
      " 4569.8576 4570.0181 4570.0289 4570.0394 4570.0605 4570.0712 4570.0817\n",
      " 4570.101  4570.1106 4570.1298 4570.1393 4570.1489 4570.1672 4570.1751\n",
      " 4570.1855 4570.1962 4570.2072 4570.2166 4570.2253 4570.247  4570.2557\n",
      " 4570.2732 4570.2819 4570.2906 4570.3154 4570.3231 4570.3311 4570.339\n",
      " 4570.3468 4570.3779 4570.3854 4570.393  4570.4006 4570.4133 4570.426\n",
      " 4570.435  4570.4437 4570.461  4570.4685 4570.4759 4570.4859 4570.4939\n",
      " 4570.5063 4570.5125 4570.5249 4570.5373 4570.5496 4570.5681 4570.5803\n",
      " 4570.5925 4570.5986 4570.6046 4570.6115 4570.6187 4570.6266 4570.6345\n",
      " 4570.6425 4570.6504 4570.6908 4570.7442 4570.7902 4570.7971 4570.8123\n",
      " 4570.8799 4570.9028 4570.9182 4570.9259 4570.9483 4570.975  4570.9884\n",
      " 4571.0675 4571.0935 4571.1708 4571.1931 4571.1985 4571.2091 4571.2196\n",
      " 4571.2383 4571.2557 4571.263  4571.2665 4571.2693 4571.2719 4571.2745\n",
      " 4571.2824 4571.285  4571.2877 4571.2902 4571.3036 4571.308  4571.3184\n",
      " 4571.3312 4571.3336 4571.338  4571.3421 4571.3458 4571.3471 4571.3492\n",
      " 4571.3576 4571.3586 4571.3637 4571.3643 4571.364  4571.3638 4571.3636\n",
      " 4571.3629 4571.3614 4571.3597 4571.3588 4571.357  4571.355  4571.353\n",
      " 4571.3511 4571.3491 4571.3482 4571.348  4571.3445 4571.3445 4571.3445\n",
      " 4571.3446 4571.3449 4571.3449 4571.3449 4571.345  4571.3462 4571.3472\n",
      " 4571.3481 4571.3479 4571.3489 4571.35   4571.3535 4571.3555 4571.3578\n",
      " 4571.36   4571.3644 4571.3667 4571.3711 4571.4148 4571.4207 4571.4239\n",
      " 4571.4256 4571.4168 4571.4157 4571.4148 4571.4131 4571.4123 4571.4114\n",
      " 4571.4094 4571.4085 4571.4076 4571.4067 4571.4057 4571.4048 4571.4041\n",
      " 4571.4034 4571.4025 4571.3909 4571.3885 4571.3849 4571.382  4571.3808\n",
      " 4571.3794 4571.3679 4571.3663 4571.3647 4571.3616 4571.36   4571.3582\n",
      " 4571.3548 4571.3531 4571.3513 4571.3493 4571.3433 4571.3413 4571.3402\n",
      " 4571.3391 4571.3381 4571.3373 4571.3367 4571.3353 4571.3343 4571.3093\n",
      " 4571.3032 4571.2995 4571.2982 4571.2973 4571.2966 4571.2964 4571.2947\n",
      " 4571.2965 4571.2964 4571.2948 4571.2949 4571.2952 4571.2955 4571.2958\n",
      " 4571.2963 4571.3045 4571.3054 4571.3064 4571.3068 4571.3024 4571.3003\n",
      " 4571.2981 4571.2959 4571.2888 4571.2867 4571.2851 4571.2821 4571.28\n",
      " 4571.2788 4571.2743 4571.2728 4571.2698 4571.2684 4571.2669 4571.2654\n",
      " 4571.2621 4571.2609 4571.2597 4571.2573 4571.2556 4571.254  4571.2471\n",
      " 4571.2436 4571.2397 4571.2288 4571.2266 4571.2249 4571.2234 4571.2221\n",
      " 4571.2209 4571.219  4571.2167 4571.2146 4571.2124 4571.1906 4571.174\n",
      " 4571.1718 4571.1696 4571.167  4571.1379 4571.1352 4571.1324 4571.1298\n",
      " 4571.1247 4571.1217 4571.1189 4571.1161 4571.1133 4571.1102 4571.1072\n",
      " 4571.1041 4571.0947 4571.0914 4571.0888 4571.0858 4571.0832 4571.0806\n",
      " 4571.0781 4571.0755 4571.0722 4571.0696 4571.067  4571.0567 4571.047\n",
      " 4571.0443 4571.0423 4571.0402 4571.0386 4571.0371 4571.0346 4571.0336\n",
      " 4571.0326 4571.0316 4571.0297 4571.029  4571.0282 4571.0272 4571.026\n",
      " 4571.0248 4571.0237 4571.0204 4571.0164 4571.0139 4571.0144 4571.0201\n",
      " 4571.02   4571.0226 4571.0328 4571.041  4571.0439 4571.0473 4571.0536\n",
      " 4571.0602 4571.0635 4571.0676 4571.0696 4571.0715 4571.0801 4571.0972\n",
      " 4571.1057 4571.1079 4571.11   4571.1185 4571.1247 4571.131 ]\n",
      "Número de coeficientes del modelo: 692\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "print(f\"Coeficientes del modelo: {model.coef_}\")\n",
    "print(f\"Intresección del modelo: {model.intercept_}\")\n",
    "print(f\"Número de coeficientes del modelo: {len(model.coef_)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8abb7ae4-3439-4487-b7cd-d815f5b2c3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score r2: nan\n",
      "Score mae: 0.0\n",
      "Score mse: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "puntuation = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Score r2: {puntuation}\")\n",
    "print(f\"Score mae: {mae}\")\n",
    "print(f\"Score mse: {mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ee01f-5f5b-4786-94b0-f90b15756a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
